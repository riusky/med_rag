from collections import Counter
from pathlib import Path
from typing import Any, Dict, List, Tuple
from prefect import task, get_run_logger
from pathlib import Path
from typing import Any, Dict, List, Tuple
from prefect import flow, task, get_run_logger
from utils.file_utils import (
    validate_input_directory,
    cleanup_empty_directories,
    get_first_level_subdirectories
)

# ------------------------ åŸºç¡€ä»»åŠ¡ ------------------------
@task(
    name="analyze-batch-results",
    description="æ‰¹é‡å¤„ç†ç»“æœç»Ÿè®¡åˆ†æï¼ˆç²¾ç®€ç‰ˆï¼‰",
    tags=["analysis", "reporting"],
)
def analyze_results(results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """PDFæ‰¹é‡å¤„ç†ç»“æœåˆ†æï¼ˆç§»é™¤äº†æ€§èƒ½ç›‘æ§æ¨¡å—ï¼‰
    
    è¾“å…¥å‚æ•°æ ¼å¼:
    [{
        "original_path": Path,      # åŸå§‹ç›®å½•è·¯å¾„
        "output_path": Path,        # ä¸­é—´è¾“å‡ºç›®å½•è·¯å¾„  
        "final_output_path": Path,  # æœ€ç»ˆè¾“å‡ºç›®å½•è·¯å¾„
        "processed_files": List[Dict],  # æˆåŠŸæ–‡ä»¶åˆ—è¡¨
        "failed_files": List[Dict]      # å¤±è´¥æ–‡ä»¶åˆ—è¡¨
    }]

    è¿”å›ç»“æ„:
    {
        "directory_stats": ç›®å½•çº§ç»Ÿè®¡,
        "file_stats": æ–‡ä»¶çº§ç»Ÿè®¡,
        "failure_analysis": å¤±è´¥åˆ†æ,
        "output_structure": è¾“å‡ºè·¯å¾„æ ·æœ¬
    }
    """
    logger = get_run_logger()
    logger.info("ğŸ“Š å¼€å§‹ç²¾ç®€ç‰ˆç»“æœåˆ†æ...")

    try:
        # ================= ç›®å½•çº§ç»Ÿè®¡ =================
        dir_stats = {
            "total_directories": len(results),
            "fully_successful_dirs": sum(1 for r in results if not r["failed_files"]),
            "partial_success_dirs": sum(1 for r in results if r["failed_files"] and r["processed_files"]),
            "fully_failed_dirs": sum(1 for r in results if not r["processed_files"] and r["failed_files"]),
            "success_rate": f"{sum(1 for r in results if not r['failed_files']) / len(results) * 100:.1f}%" 
                          if results else "0%"
        }

        # ================= æ–‡ä»¶çº§ç»Ÿè®¡ ================= 
        total_files = sum(len(r["processed_files"]) + len(r["failed_files"]) for r in results)
        success_files = sum(len(r["processed_files"]) for r in results)
        
        file_stats = {
            "total_files": total_files,
            "success_files": success_files,
            "failed_files": total_files - success_files,
            "success_rate": f"{success_files / total_files * 100:.1f}%" if total_files else "0%"
        }

        # ================= å¤±è´¥åˆ†æ =================
        failure_analysis = {}
        if total_files > success_files:
            all_failures = [f for r in results for f in r["failed_files"]]
            error_types = Counter(
                f.get("error", "unknown").split(":")[0].strip() 
                for f in all_failures
            )
            
            failure_analysis = {
                "top_error_types": dict(error_types.most_common(3)),
                "most_affected_directory": max(
                    results,
                    key=lambda x: len(x["failed_files"]),
                    default={"original_path": Path("N/A")}
                )["original_path"].name,
                "failure_examples": [
                    {"file": f["pdf_stem"], "error": f.get("error")} 
                    for f in all_failures[:3]
                ]
            }

        # ================= æ„å»ºæŠ¥å‘Š =================
        report = {
            "directory_stats": dir_stats,
            "file_stats": file_stats,
            "failure_analysis": failure_analysis,
            "output_structure": {
                "input_root": str(results[0]["original_path"].parent) if results else None,
                "output_root": str(results[0]["output_path"].parent) if results else None
            }
        }

        logger.info(
            f"âœ… åˆ†æå®Œæˆ | ç›®å½•æˆåŠŸç‡: {dir_stats['success_rate']} | "
            f"æ–‡ä»¶æˆåŠŸç‡: {file_stats['success_rate']}"
        )
        logger.debug("å…³é”®æŒ‡æ ‡:\n" + "\n".join(
            f"{k}: {v}" for k,v in report.items() 
            if k != "failure_examples"
        ))

        return report

    except Exception as e:
        logger.error(f"åˆ†æå¼‚å¸¸: {str(e)}")
        return {
            "error": str(e),
            "partial_results": {
                "processed_files": sum(len(r["processed_files"]) for r in results),
                "failed_files": sum(len(r["failed_files"]) for r in results)
            } if results else None
        }
    
@task(
    name="prepare-output-path",
    description="ç”Ÿæˆä¿ç•™åŸå§‹ç›®å½•ç»“æ„çš„è¾“å‡ºè·¯å¾„",
    tags=["path-processing"]
)
def prepare_output_path(input_dir: Path, pdf_file: Path, output_root: Path) -> Path:
    """æ„å»ºä¸åŸå§‹ç›®å½•ç»“æ„åŒ¹é…çš„è¾“å‡ºè·¯å¾„
    
    Args:
        input_dir: åŸå§‹è¾“å…¥æ ¹ç›®å½•
        pdf_file: å½“å‰å¤„ç†çš„PDFæ–‡ä»¶è·¯å¾„
        output_root: è¾“å‡ºæ ¹ç›®å½•
        
    Returns:
        å¯¹åº”è¾“å…¥ç»“æ„çš„è¾“å‡ºå­ç›®å½•è·¯å¾„
        
    Raises:
        ValueError: å½“æ–‡ä»¶ä¸åœ¨è¾“å…¥ç›®å½•ä¸‹æ—¶
        PermissionError: ç›®å½•åˆ›å»ºæƒé™ä¸è¶³æ—¶
    """
    logger = get_run_logger()
    logger.info(f"ğŸ“‚ å¼€å§‹æ„å»ºè¾“å‡ºè·¯å¾„ | è¾“å…¥æ–‡ä»¶: {pdf_file}")
    
    try:
        # è®¡ç®—ç›¸å¯¹è·¯å¾„
        relative_path = pdf_file.relative_to(input_dir).parent
        logger.debug(f"åŸå§‹è·¯å¾„è§£æ„æˆåŠŸ | ç›¸å¯¹è·¯å¾„: {relative_path}")
        
        # æ„å»ºè¾“å‡ºè·¯å¾„
        output_path = output_root / relative_path
        logger.info(f"ç›®æ ‡è¾“å‡ºè·¯å¾„: {output_path}")
        
        # åˆ›å»ºç›®å½•ï¼ˆåŒ…å«æƒé™éªŒè¯ï¼‰
        output_path.mkdir(parents=True, exist_ok=True)
        if not output_path.exists():
            raise PermissionError(f"ç›®å½•åˆ›å»ºå¤±è´¥: {output_path}")
            
        logger.info(f"âœ… è¾“å‡ºè·¯å¾„å‡†å¤‡å®Œæˆ: {output_path}")
        return output_path
        
    except ValueError as ve:
        logger.critical(f"è·¯å¾„è®¡ç®—é”™è¯¯: {pdf_file} ä¸åœ¨è¾“å…¥ç›®å½• {input_dir} ä¸‹")
        raise ValueError(f"æ–‡ä»¶è·¯å¾„è¶Šç•Œ: {pdf_file}") from ve
    except PermissionError as pe:
        logger.error(f"æƒé™ä¸è¶³æ— æ³•åˆ›å»ºç›®å½•: {output_path} | é”™è¯¯: {str(pe)}")
        raise
    except Exception as e:
        logger.error(f"æœªçŸ¥è·¯å¾„å¤„ç†é”™è¯¯: {str(e)}", exc_info=True)
        raise RuntimeError(f"è¾“å‡ºè·¯å¾„ç”Ÿæˆå¤±è´¥: {pdf_file}") from e

@task(
    name="perform-cleanup",
    description="æ¸…ç†ç©ºç›®å½•ä»»åŠ¡",
    tags=["maintenance"]
)
def perform_cleanup(output_root: Path) -> None:
    """å®‰å…¨æ¸…ç†è¾“å‡ºç›®å½•ä¸­çš„ç©ºç›®å½•
    
    Args:
        output_root: éœ€è¦æ¸…ç†çš„æ ¹ç›®å½•è·¯å¾„
        
    Raises:
        RuntimeError: æ¸…ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸å¯æ¢å¤é”™è¯¯æ—¶
    """
    logger = get_run_logger()
    logger.info(f"ğŸ§¹ å¼€å§‹æ¸…ç†ç›®å½•: {output_root}")
    
    try:
        removed_dirs = cleanup_empty_directories(output_root)
        logger.info(f"æ¸…ç†å®Œæˆ | ç§»é™¤ç©ºç›®å½•æ•°: {len(removed_dirs)}")
        
        if removed_dirs:
            logger.debug("è¢«æ¸…ç†çš„ç›®å½•åˆ—è¡¨:\n" + "\n".join([str(p) for p in removed_dirs]))
            
    except PermissionError as pe:
        logger.error(f"ç›®å½•æ¸…ç†æƒé™ä¸è¶³: {output_root} | é”™è¯¯: {str(pe)}")
    except FileNotFoundError as fnf:
        logger.warning(f"ç›®å½•ä¸å­˜åœ¨: {output_root} | é”™è¯¯: {str(fnf)}")
    except Exception as e:
        logger.error(f"æ¸…ç†è¿‡ç¨‹å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}", exc_info=True)
        raise RuntimeError("ç›®å½•æ¸…ç†å¤±è´¥") from e

@task(
    name="validate-input-directory",
    description="éªŒè¯è¾“å…¥ç›®å½•æœ‰æ•ˆæ€§ï¼ˆä¿®å¤ç‰ˆï¼‰",
    tags=["validation"]
)
def validate_input_dir(input_dir: Path) -> Path:
    """éªŒè¯è¾“å…¥ç›®å½•æ˜¯å¦åˆæ³•å¯ç”¨
    
    Args:
        input_dir: å¾…éªŒè¯çš„ç›®å½•è·¯å¾„
        
    Returns:
        è§£æåçš„ç»å¯¹è·¯å¾„
        
    Raises:
        FileNotFoundError: ç›®å½•ä¸å­˜åœ¨æ—¶
        NotADirectoryError: è·¯å¾„ä¸æ˜¯ç›®å½•æ—¶
    """
    logger = get_run_logger()
    logger.info(f"ğŸ” å¼€å§‹éªŒè¯è¾“å…¥ç›®å½•: {input_dir}")
    
    try:
        # å…ˆè§£æè·¯å¾„ç¡®ä¿æ˜¯æœ‰æ•ˆçš„Pathå¯¹è±¡
        input_path = Path(input_dir).resolve()
        
        # éªŒè¯ç›®å½•æœ‰æ•ˆæ€§ï¼ˆå‡è®¾validate_input_directoryè¿”å›å¸ƒå°”å€¼ï¼‰
        if not validate_input_directory(input_path):
            raise NotADirectoryError(f"æ— æ•ˆçš„ç›®å½•è·¯å¾„: {input_path}")
            
        logger.info(f"âœ… éªŒè¯é€šè¿‡ | æœ‰æ•ˆç›®å½•: {input_path}")
        return input_path
        
    except FileNotFoundError as fnf:
        logger.error(f"ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        raise
    except NotADirectoryError as nde:
        logger.error(f"è·¯å¾„ä¸æ˜¯æœ‰æ•ˆç›®å½•: {input_dir}")
        raise
    except Exception as e:
        logger.error(f"ç›®å½•éªŒè¯å¼‚å¸¸: {str(e)}", exc_info=True)
        raise

@task(
    name="get-subdirectories",
    description="è·å–æœ‰æ•ˆå­ç›®å½•åˆ—è¡¨",
    tags=["directory-processing"]
)
def get_subdirectories(parent_dir: Path) -> List[Path]:
    """è·å–ä¸€çº§æœ‰æ•ˆå­ç›®å½•åˆ—è¡¨
    
    Args:
        parent_dir: çˆ¶ç›®å½•è·¯å¾„
        
    Returns:
        å­ç›®å½•è·¯å¾„åˆ—è¡¨ï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
        
    Raises:
        FileNotFoundError: çˆ¶ç›®å½•ä¸å­˜åœ¨æ—¶
    """
    logger = get_run_logger()
    logger.info(f"ğŸ“‚ æ‰«æå­ç›®å½•: {parent_dir}")
    
    try:
        dirs = get_first_level_subdirectories(parent_dir)
        
        if not dirs:
            logger.warning(f"æœªæ‰¾åˆ°æœ‰æ•ˆå­ç›®å½•: {parent_dir}")
        else:
            logger.info(f"æ‰¾åˆ° {len(dirs)} ä¸ªå­ç›®å½• | é¦–ä¸ªå­ç›®å½•: {dirs[0].name}")
            
        return dirs
        
    except FileNotFoundError as fnf:
        logger.error(f"çˆ¶ç›®å½•ä¸å­˜åœ¨: {parent_dir}")
        raise
    except Exception as e:
        logger.error(f"è·å–å­ç›®å½•å¤±è´¥: {str(e)}", exc_info=True)
        raise

@task(
    name="convert-paths",
    description="è·¯å¾„æ ¼å¼è½¬æ¢ä»»åŠ¡",
    tags=["path-processing"]
)
def convert_paths(input_dir: str, output_root: str) -> Tuple[Path, Path]:
    """å°†å­—ç¬¦ä¸²è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡
    
    Args:
        input_dir: è¾“å…¥ç›®å½•å­—ç¬¦ä¸²è·¯å¾„
        output_root: è¾“å‡ºæ ¹ç›®å½•å­—ç¬¦ä¸²è·¯å¾„
        
    Returns:
        (è¾“å…¥ç›®å½•Pathå¯¹è±¡, è¾“å‡ºç›®å½•Pathå¯¹è±¡)
        
    Raises:
        ValueError: è·¯å¾„æ— æ•ˆæ—¶
    """
    logger = get_run_logger()
    logger.info(f"ğŸ”„ å¼€å§‹è·¯å¾„è½¬æ¢ | è¾“å…¥: {input_dir} â†’ è¾“å‡º: {output_root}")
    
    try:
        input_path = Path(input_dir).expanduser().resolve()
        output_path = Path(output_root).expanduser().resolve()
        
        logger.debug(f"è§£æåè·¯å¾„ | è¾“å…¥: {input_path} | è¾“å‡º: {output_path}")
        
        if not input_path.exists():
            raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {input_path}")
            
        if not output_path.exists():
            logger.warning(f"è¾“å‡ºè·¯å¾„ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨åˆ›å»º: {output_path}")
            output_path.mkdir(parents=True, exist_ok=True)
            
        return input_path, output_path
        
    except FileNotFoundError as fnf:
        logger.error(f"è·¯å¾„ä¸å­˜åœ¨: {str(fnf)}")
        raise
    except Exception as e:
        logger.error(f"è·¯å¾„è½¬æ¢å¼‚å¸¸: {str(e)}", exc_info=True)
        raise ValueError("è·¯å¾„è½¬æ¢å¤±è´¥") from e

@task(
    name="collect-all-pdfs",
    description="èšåˆPDFæ–‡ä»¶ä»»åŠ¡",
    tags=["file-processing"],
)
def collect_all_pdf_files(subdirs: List[Path]) -> List[Dict[str, Any]]:
    """åˆ†å¸ƒå¼æ”¶é›†æ‰€æœ‰PDFæ–‡ä»¶
    
    Args:
        subdirs: å¾…æ‰«æçš„å­ç›®å½•åˆ—è¡¨
        
    Returns:
        ç»“æ„åŒ–æ”¶é›†ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
        {
            "path": å­ç›®å½•è·¯å¾„,
            "files": PDFæ–‡ä»¶åˆ—è¡¨,
            "count": æ–‡ä»¶æ•°é‡
        }
    """
    logger = get_run_logger()
    logger.info(f"ğŸ” å¼€å§‹å…¨å±€PDFæ–‡ä»¶æ”¶é›† | å¾…æ‰«æç›®å½•æ•°: {len(subdirs)}")
    
    results = []
    total_files = 0
    
    try:
        for idx, subdir in enumerate(subdirs, 1):
            logger.debug(f"æ­£åœ¨æ‰«æ ({idx}/{len(subdirs)}) â” {subdir.name}")
            
            files = collect_pdf_files(subdir)
            file_count = len(files)
            total_files += file_count
            
            results.append({
                "path": subdir,
                "files": files,
                "count": file_count
            })
            
            logger.debug(f"æ‰«æå®Œæˆ | ç›®å½•: {subdir.name} | æ–‡ä»¶æ•°: {file_count}")
            
        logger.info(f"âœ… æ–‡ä»¶æ”¶é›†å®Œæˆ | æ€»æ–‡ä»¶æ•°: {total_files} | æœ‰æ•ˆç›®å½•æ•°: {len(results)}")
        return results
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {str(e)}", exc_info=True)
        raise

@task(
    name="collect-pdfs",
    description="PDFæ–‡ä»¶æ”¶é›†å­ä»»åŠ¡",
    tags=["file-processing"],
)
def collect_pdf_files(subdir: Path, pattern: str = "*.pdf") -> List[Path]:
    """æ‰«ææŒ‡å®šç›®å½•è·å–PDFæ–‡ä»¶åˆ—è¡¨
    
    Args:
        subdir: ç›®æ ‡ç›®å½•
        pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆé»˜è®¤*.pdfï¼‰
        
    Returns:
        æŒ‰åç§°æ’åºçš„PDFæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    logger = get_run_logger()
    logger.info(f"ğŸ“‚ å¼€å§‹æ‰«æç›®å½•: {subdir}")
    
    try:
        if not subdir.is_dir():
            raise NotADirectoryError(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {subdir}")
            
        files = sorted([f for f in subdir.glob(pattern) if f.is_file()])
        valid_files = []
        
        # æ–‡ä»¶æœ‰æ•ˆæ€§æ£€æŸ¥
        for f in files:
            if f.stat().st_size == 0:
                logger.warning(f"è·³è¿‡ç©ºæ–‡ä»¶: {f.name}")
                continue
            valid_files.append(f)
            
        logger.info(f"æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ•ˆPDFæ–‡ä»¶ | ç›®å½•: {subdir.name}")
        return valid_files
        
    except NotADirectoryError as nde:
        logger.error(f"è·¯å¾„ä¸æ˜¯ç›®å½•: {subdir}")
        raise
    except PermissionError as pe:
        logger.error(f"ç›®å½•è®¿é—®æƒé™ä¸è¶³: {subdir}")
        raise
    except Exception as e:
        logger.error(f"æ–‡ä»¶æ‰«æå¼‚å¸¸: {str(e)}", exc_info=True)
        raise